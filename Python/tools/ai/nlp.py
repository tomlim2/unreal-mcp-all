"""
MegaMelange Natural Language Processing Module

## Target User & Design Philosophy

**Primary User**: Creative professionals in their 20's (directors, cinematographers, technical artists) 
working with Unreal Engine for film, game development, and virtual production.

**Core Principles**:
- **Intuitive Creative Control**: Natural language commands for complex Unreal Engine operations
- **Professional Workflow Integration**: Support for industry-standard pipelines and tools
- **Real-time Iteration**: Immediate visual feedback for creative decision-making
- **Modular Extensibility**: Easy addition of new creative tools and rendering features
- **Cross-Platform Accessibility**: Web interface, MCP clients, and direct API access

This module translates natural language input from creative professionals into structured
Unreal Engine commands, enabling intuitive control over lighting, camera work, materials,
and scene composition through conversational interfaces.
"""

import logging
import json
import os
import sys
from typing import Dict, List, Any, Optional
from .command_handlers import get_command_registry
from .session_management.utils.path_manager import get_path_manager
from core.errors import AppError, ErrorCategory

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    # Load .env file from the Python directory
    dotenv_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')
    load_dotenv(dotenv_path)
    print(f"âœ… Loaded .env file from: {dotenv_path}")
except ImportError:
    print("âš ï¸ python-dotenv not installed, .env file will not be loaded")
except Exception as e:
    print(f"âš ï¸ Failed to load .env file: {e}")

# Try to import anthropic at module level to debug the issue
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
    print(f"âœ… Anthropic SDK imported successfully in {__name__}")
except ImportError as e:
    ANTHROPIC_AVAILABLE = False
    print(f"âŒ Failed to import Anthropic SDK in {__name__}: {e}")
    print(f"Python path: {sys.path[:3]}")

# Get logger
logger = logging.getLogger("UnrealMCP")

def _attempt_json_completion(incomplete_json: str) -> str:
    """Attempt to complete an incomplete JSON response."""
    try:
        # Remove any trailing incomplete content
        content = incomplete_json.strip()
        
        # Find the last complete structure
        last_quote_pos = -1
        in_string = False
        escaped = False
        
        for i, char in enumerate(content):
            if escaped:
                escaped = False
                continue
            
            if char == '\\':
                escaped = True
                continue
                
            if char == '"' and not escaped:
                if not in_string:
                    in_string = True
                else:
                    in_string = False
                    last_quote_pos = i
        
        # If we're in the middle of a string, complete it
        if in_string and last_quote_pos != -1:
            # Find where the incomplete string starts
            string_start = content.rfind('"', 0, last_quote_pos)
            if string_start != -1:
                # Complete the string
                content = content[:string_start + 1] + content[string_start + 1:] + '"'
        
        # Now fix structural issues
        open_braces = content.count('{')
        close_braces = content.count('}')
        open_brackets = content.count('[')
        close_brackets = content.count(']')
        
        # Complete missing closing braces/brackets
        missing_braces = open_braces - close_braces
        missing_brackets = open_brackets - close_brackets
        
        # Add missing closes in logical order
        if missing_brackets > 0:
            content += ']' * missing_brackets
        if missing_braces > 0:
            content += '}' * missing_braces
            
        return content
        
    except Exception as e:
        logger.warning(f"JSON completion failed: {e}")
        return incomplete_json

def _resolve_image_path(filename: str) -> str:
    """Resolve image path based on file source - Unreal screenshots vs styled images."""
    import os

    # Get project paths using centralized path management (with built-in fallbacks)
    path_manager = get_path_manager()
    screenshots_dir_path = path_manager.get_unreal_screenshots_path()
    styled_dir_path = path_manager.get_unreal_styled_images_path()

    # If centralized path management fails completely, return filename as-is
    if not screenshots_dir_path or not styled_dir_path:
        return filename

    # Just filename provided - need to determine the correct directory
    if not os.path.dirname(filename):
        # Check if this looks like a styled image (generated by 2D editing)
        if 'styled_' in filename or filename.endswith('_styled.png') or filename.endswith('_styled.jpg'):
            # This is a styled image - look in styled directory
            styled_path = os.path.join(styled_dir_path, filename)
            if os.path.exists(styled_path):
                return styled_path

        # Check standard Unreal screenshots directory first
        unreal_path = os.path.join(screenshots_dir_path, filename)
        if os.path.exists(unreal_path):
            return unreal_path

        # Check styled directory as fallback
        styled_path = os.path.join(styled_dir_path, filename)
        if os.path.exists(styled_path):
            return styled_path

        # If file doesn't exist in either location, default to Unreal screenshots
        # (the command handler will handle the file not found error)
        return unreal_path

    # Full or relative path provided - return as-is
    return filename

def _extract_from_partial_response(partial_response: str) -> dict:
    """Extract meaningful information from a partial/malformed AI response."""
    try:
        import re
        
        # Default response structure
        result = {
            "explanation": "Processing your request based on partial AI response",
            "commands": [],
            "expectedResult": "Command extracted from incomplete response"
        }
        
        # Try to extract explanation
        explanation_match = re.search(r'"explanation":\s*"([^"]*)', partial_response)
        if explanation_match:
            result["explanation"] = explanation_match.group(1)
        
        # Try to extract command type and parameters
        command_type_match = re.search(r'"type":\s*"([^"]*)', partial_response)
        if command_type_match:
            command_type = command_type_match.group(1)
            
            # Initialize command structure
            command = {
                "type": command_type,
                "params": {}
            }
            
            # Extract common parameters based on command type
            if command_type == "transform_image_style":
                # Extract style_prompt
                style_match = re.search(r'"style_prompt":\s*"([^"]*)', partial_response)
                if style_match:
                    command["params"]["style_prompt"] = style_match.group(1)
                else:
                    # Infer from content - look for style descriptions
                    if "Japan" in partial_response or "punk" in partial_response:
                        command["params"]["style_prompt"] = "Japan punk style"
                
                # Extract image_path (or image_url which should be converted to image_path)
                image_path_match = re.search(r'"image_path":\s*"([^"]*)', partial_response)
                image_url_match = re.search(r'"image_url":\s*"([^"]*)', partial_response)
                
                if image_path_match:
                    command["params"]["image_path"] = _resolve_image_path(image_path_match.group(1))
                elif image_url_match:
                    # Convert image_url parameter to image_path (the handler expects image_path)
                    command["params"]["image_path"] = _resolve_image_path(image_url_match.group(1))
                else:
                    # This will be handled by the handler using session context for latest image
                    pass
                
                # Add default parameters
                command["params"]["intensity"] = 0.8
                
            elif command_type == "take_screenshot":
                # Extract resolution multiplier
                res_match = re.search(r'"resolution_multiplier":\s*([0-9.]+)', partial_response)
                if res_match:
                    command["params"]["resolution_multiplier"] = float(res_match.group(1))
                else:
                    command["params"]["resolution_multiplier"] = 2.0
                command["params"]["include_ui"] = False

            elif command_type == "generate_video_from_image":
                # Extract prompt (required)
                prompt_match = re.search(r'"prompt":\s*"([^"]*)', partial_response)
                if prompt_match:
                    command["params"]["prompt"] = prompt_match.group(1)

                # Extract image_url (optional)
                image_url_match = re.search(r'"image_url":\s*"([^"]*)', partial_response)
                if image_url_match:
                    command["params"]["image_url"] = image_url_match.group(1)

                # Extract aspect_ratio (optional)
                aspect_ratio_match = re.search(r'"aspect_ratio":\s*"([^"]*)', partial_response)
                if aspect_ratio_match:
                    command["params"]["aspect_ratio"] = aspect_ratio_match.group(1)

                # Extract resolution (optional)
                resolution_match = re.search(r'"resolution":\s*"([^"]*)', partial_response)
                if resolution_match:
                    command["params"]["resolution"] = resolution_match.group(1)
            
            result["commands"] = [command]
            result["expectedResult"] = f"Executing {command_type} based on partial response"
        
        logger.info(f"Extracted command from partial response: {result}")
        return result
        
    except Exception as e:
        logger.error(f"Failed to extract from partial response: {e}")
        return {
            "explanation": "Unable to process the request due to response parsing error",
            "commands": [],
            "expectedResult": "Please try rephrasing your request"
        }

# Import session management
from .session_management import get_session_manager, SessionContext

# Import model providers
from .model_providers import get_model_provider, get_default_model, get_available_models


def _auto_assign_latest_image_if_needed(command, session_context):
    """ì´ë¯¸ì§€ ê´€ë ¨ ëª…ë ¹ì— ìµœì‹  ì´ë¯¸ì§€ UID ìžë™ í• ë‹¹

    IMPORTANT: Only assigns image UIDs (img_XXX), never video UIDs (vid_XXX).
    """
    if not command.get("params"):
        command["params"] = {}

    params = command["params"]
    command_type = command.get("type")

    # image_urlì´ ì—†ëŠ” ì´ë¯¸ì§€ ê´€ë ¨ ëª…ë ¹ë“¤
    image_commands = ["transform_image_style", "generate_video_from_image"]

    # Check for both old and new parameter names
    has_image = ("image_url" in params or "image_uid" in params or
                 "target_image_uid" in params or "main_image_data" in params)

    if command_type in image_commands and not has_image:
        logger.info(f"Attempting auto-assignment for {command_type} (has_image={has_image}, session_context={session_context is not None})")

        latest_uid = None

        # Try 1: Get from session conversation history (preferred for session-based workflow)
        if session_context:
            latest_uid = session_context.get_latest_image_uid()
            logger.info(f"Retrieved from session context: latest_uid={latest_uid}")

        # Try 2: Get from UID manager directly (fallback for global latest image)
        if not latest_uid:
            from tools.ai.uid_manager import get_latest_image_uid as get_global_latest_image_uid
            latest_uid = get_global_latest_image_uid()
            logger.info(f"Retrieved from UID manager: latest_uid={latest_uid}")

        # Double-check: ensure we only use image UIDs, never video UIDs
        if latest_uid and latest_uid.startswith('img_'):
            # For transform_image_style, use target_image_uid (new system)
            if command_type == "transform_image_style":
                params["target_image_uid"] = latest_uid
                logger.info(f"âœ… Auto-assigned latest image UID for {command_type}: {latest_uid}")
            # For generate_video_from_image, use image_url
            elif command_type == "generate_video_from_image":
                params["image_url"] = latest_uid
                logger.info(f"âœ… Auto-assigned latest image UID for {command_type}: {latest_uid}")
        else:
            logger.warning(f"âŒ No valid image UID found for {command_type} (latest_uid: {latest_uid})")


def _extract_style_essence(user_input: str, provider) -> str:
    """Extract only style-related content from user input to reduce tokens."""
    try:
        # Very minimal prompt for style extraction
        extraction_prompt = """Extract only the visual style/effect from this request. Keep it under 10 words.

Examples:
- "Make it cyberpunk style with neon lights" â†’ "cyberpunk neon"
- "ì‚¬ì´ë²„íŽ‘í¬ ìŠ¤íƒ€ì¼ë¡œ ë°”ê¿”ì¤˜" â†’ "cyberpunk style"  
- "Apply watercolor effect to the image" â†’ "watercolor effect"
- "Transform to anime style" â†’ "anime style"

Input: {input}
Style:"""

        messages = [{
            "role": "user", 
            "content": extraction_prompt.format(input=user_input)
        }]
        
        # Use minimal tokens for extraction
        style_essence = provider.generate_response(
            messages=messages,
            system_prompt="Extract visual style keywords only. Be concise.",
            max_tokens=50,  # Very small - just need style keywords
            temperature=0.0  # Deterministic
        )
        
        # Clean up the response
        style_essence = style_essence.strip().strip('"').strip("'")
        
        # Fallback if extraction failed
        if not style_essence or len(style_essence) > 50:
            # Simple keyword extraction fallback
            style_keywords = ['cyberpunk', 'anime', 'watercolor', 'punk', 'neon', 'vintage', 'dark', 'bright']
            found_keywords = [kw for kw in style_keywords if kw in user_input.lower()]
            style_essence = ' '.join(found_keywords) if found_keywords else user_input
        
        logger.info(f"Style extraction: '{user_input}' â†’ '{style_essence}'")
        return style_essence
        
    except Exception as e:
        logger.warning(f"Style extraction failed: {e}")
        return user_input  # Fallback to original


def _process_images_for_commands(commands: List[Dict[str, Any]], images: Optional[List[Dict[str, Any]]], reference_images: Optional[List[Dict[str, Any]]], target_image_uid: str = None, main_image_data: Optional[Dict[str, Any]] = None) -> None:
    """
    Inject image data into commands that support image processing.

    Args:
        commands: List of AI-generated commands to process
        images: List of target images with 'mime_type', 'data', optional 'purpose'
        reference_images: List of reference images with 'mime_type', 'data', optional 'purpose'
        target_image_uid: Optional UID for main target image
        main_image_data: Optional user-uploaded main image (in-memory only, no UID)
    """
    if not images and not reference_images and not target_image_uid and not main_image_data:
        return

    # Commands that support image processing
    image_commands = {
        'transform_image_style',
        'compose_images',
        'blend_images',
        'transfer_style'
    }

    for command in commands:
        command_type = command.get('type')

        if command_type in image_commands:
            if 'params' not in command:
                command['params'] = {}

            # Priority 1: Add user-uploaded main image (in-memory, no UID) - takes precedence over auto-fetched UID
            if main_image_data:
                command['params']['main_image_data'] = main_image_data
                logger.info(f"Added user-uploaded main image ({main_image_data.get('mime_type')}, {len(main_image_data.get('data', b''))//1024}KB) to command {command_type}")
            # Priority 2: Add target image UID if provided (existing screenshot or auto-fetched)
            elif target_image_uid:
                command['params']['target_image_uid'] = target_image_uid
                logger.info(f"Added target image UID {target_image_uid} to command {command_type}")
            # Priority 3: Add target image data (legacy method)
            elif images:
                target_image = images[0]
                command['params']['target_image'] = {
                    'data': target_image['data'],
                    'mime_type': target_image['mime_type']
                }
                # Remove base64 for logging
                logger.info(f"Added target image ({target_image['mime_type']}, {len(target_image['data'])//1024}KB) to command {command_type}")

            # Add reference images (up to 3 for Gemini API limit)
            if reference_images:
                processed_refs = []
                for ref_img in reference_images[:3]:  # Gemini supports max 3 images
                    processed_ref = {}

                    # Data-based reference images
                    if 'data' in ref_img:
                        processed_ref['data'] = ref_img['data']
                        processed_ref['mime_type'] = ref_img.get('mime_type', 'image/png')

                    if 'purpose' in ref_img:
                        processed_ref['purpose'] = ref_img['purpose']
                    if 'mime_type' in ref_img:
                        processed_ref['mime_type'] = ref_img['mime_type']

                    processed_refs.append(processed_ref)

                command['params']['reference_images'] = processed_refs
                logger.info(f"Added {len(processed_refs)} reference images to command {command_type}")

            # For backward compatibility, also set image_url to None (no UID needed)
            if 'image_url' in command.get('params', {}):
                command['params']['image_url'] = None


def _process_natural_language_impl(user_input: str, context: str = None, session_id: str = None, llm_model: str = None, images: Optional[List[Dict[str, Any]]] = None, reference_images: Optional[List[Dict[str, Any]]] = None, target_image_uid: str = None, main_image_data: Optional[Dict[str, Any]] = None, main_prompt: str = None, reference_prompts: List[str] = None) -> Dict[str, Any]:
    try:
        # Get session manager and session context if session_id provided
        session_manager = None
        session_context = None
        if session_id:
            session_manager = get_session_manager()
            session_context = session_manager.get_or_create_session(session_id)
            logger.info(f"Using session context: {session_id}")
        else:
            logger.info("No session ID provided, processing without session context")
        
        # Determine which model to use
        selected_model = llm_model or get_default_model()
        logger.info(f"Using model: {selected_model}")

        # Get the model provider
        provider = get_model_provider(selected_model)
        if not provider:
            # If user explicitly requested a specific model, return error (no fallback)
            if llm_model:
                return {
                    "error": f"Requested model '{llm_model}' is not available or not configured",
                    "explanation": f"The '{llm_model}' model is not available. Please check your API key configuration.",
                    "commands": [],
                    "executionResults": [],
                    "modelUsed": llm_model
                }
            else:
                # If using default model and it's not available, return configuration error
                return {
                    "error": f"Default model '{selected_model}' is not available. Configure GOOGLE_API_KEY or ANTHROPIC_API_KEY",
                    "explanation": "Natural language processing unavailable - no AI models configured",
                    "commands": [],
                    "executionResults": [],
                    "modelUsed": "none"
                }
        
        # Determine if this is a style request for preprocessing
        is_style_request = any(keyword in user_input.lower() for keyword in ['style', 'cyberpunk', 'anime', 'watercolor', 'punk', 'transform', 'make it', 'nano banana', 'nano-banana'])

        # Determine if this is a video generation request
        is_video_request = any(keyword in user_input.lower() for keyword in ['video', 'animate', 'motion', 'movement', 'fly through', 'camera movement', 'flying camera', 'moving'])
        
        # Build system prompt with session context
        system_prompt = build_system_prompt_with_session(context or "Assume as you are a creative cinematic director", session_context, is_style_request or is_video_request)
        logger.info(f"Processing natural language input with {provider.get_model_name()}: {user_input}")
        processed_input = user_input
        
        # For style requests, extract only the style essence to reduce tokens
        if is_style_request and session_context and session_context.get_latest_image_path():
            processed_input = _extract_style_essence(user_input, provider)
            logger.info(f"Style preprocessing: '{user_input}' â†’ '{processed_input}'")
        
        # Build messages list including conversation history
        messages = []
        
        # Add conversation history as proper messages
        if session_context and session_context.conversation_history:
            # For style requests, use minimal history
            max_history = 2 if is_style_request else 4
            recent_messages = session_context.conversation_history[-max_history:]
            for msg in recent_messages:
                if msg.role in ['user', 'assistant']:
                    messages.append({
                        "role": msg.role,
                        "content": msg.content
                    })
        
        # Add current user input as the final message
        messages.append({
            "role": "user", 
            "content": f"User request: {processed_input}"
        })
        
        # Generate AI response using the selected provider
        ai_response = provider.generate_response(
            messages=messages,
            system_prompt=system_prompt,
            max_tokens=4096,  # Increased to handle longer responses
            temperature=0.1
        )
        logger.info(f"AI response from {provider.get_model_name()} for '{user_input}': {ai_response}")

        # Parse AI response
        try:
            parsed_response = json.loads(ai_response)
        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse AI response as JSON: {e}")
            logger.warning(f"Raw AI response: {repr(ai_response)}")
            
            # Try to fix common JSON issues first
            fixed_response = ai_response.strip()
            
            # Implement comprehensive JSON completion
            fixed_response = _attempt_json_completion(fixed_response)
            
            # Try parsing the fixed response
            try:
                parsed_response = json.loads(fixed_response)
                logger.info("Successfully fixed and parsed JSON response")
            except json.JSONDecodeError:
                # Try to extract JSON from response (which often includes explanatory text)
                import re
                json_match = re.search(r'\{[\s\S]*\}', ai_response)
                if json_match:
                    try:
                        json_text = json_match.group()
                        parsed_response = json.loads(json_text)
                        logger.info("Successfully extracted JSON from AI response")
                    except json.JSONDecodeError:
                        logger.warning("Extracted text is also not valid JSON")
                        # Fall back to content extraction
                        parsed_response = _extract_from_partial_response(ai_response)
                else:
                    # No JSON structure found, fall back to content extraction
                    parsed_response = _extract_from_partial_response(ai_response)

        # Process images for commands if images are provided
        if (images or reference_images or target_image_uid or main_image_data) and parsed_response.get("commands"):
            _process_images_for_commands(parsed_response["commands"], images, reference_images, target_image_uid, main_image_data)

        # Execute commands using direct connection with schema validation
        execution_results = []
        if parsed_response.get("commands") and isinstance(parsed_response["commands"], list):
            for command in parsed_response["commands"]:
                try:
                    logger.info(f"Executing command from NLP: {command}")

                    # Add session_id to command params if session_id is provided
                    if session_id:
                        if "params" not in command:
                            command["params"] = {}
                        command["params"]["session_id"] = session_id
                        logger.debug(f"Added session_id {session_id} to command {command.get('type')}")

                    # Add new prompt fields for enhanced reference images flow
                    if main_prompt is not None or reference_prompts is not None:
                        if "params" not in command:
                            command["params"] = {}

                        if main_prompt is not None:
                            command["params"]["main_prompt"] = main_prompt
                            logger.info(f"ðŸŽ¯ Added main_prompt to {command.get('type')}: '{main_prompt}'")

                        if reference_prompts is not None and len(reference_prompts) > 0:
                            # Filter out empty prompts
                            non_empty_prompts = [p for p in reference_prompts if p and p.strip()]
                            if non_empty_prompts:
                                command["params"]["reference_prompts"] = non_empty_prompts
                                logger.info(f"ðŸŽ¯ Added {len(non_empty_prompts)} reference_prompts to {command.get('type')}: {non_empty_prompts}")

                    # Auto-assign latest image for image-related commands if needed
                    _auto_assign_latest_image_if_needed(command, session_context)
                    
                    # Session tracking is now handled by the simple command handlers
                    
                    # Commands are now validated by handler system in execute_command_direct
                    # No need for pre-validation here as handlers manage their own validation
                    
                    result = execute_command_direct(command)
                    execution_results.append({
                        "command": command.get("type", "unknown"),
                        "success": True,
                        "result": result,
                        "validation": "passed"
                    })
                    logger.info(f"Successfully executed validated command: {command.get('type')}")
                except AppError as e:
                    # Handle structured errors from command handlers
                    e.log()
                    error_response = e.to_response()["error"]  # Get structured error format
                    execution_results.append({
                        "command": command.get("type", "unknown"),
                        "success": False,
                        "error": error_response["message"],
                        "error_code": error_response["code"],
                        "category": error_response["category"],
                        "error_details": error_response.get("details"),
                        "suggestion": error_response.get("suggestion"),
                        "validation": "passed"  # AppError means validation passed but execution failed
                    })
                except Exception as e:
                    # Handle unexpected errors
                    logger.error(f"Failed to execute command {command.get('type')}: {e}")
                    execution_results.append({
                        "command": command.get("type", "unknown"),
                        "success": False,
                        "error": str(e),
                        "validation": "failed" if "validation failed" in str(e).lower() else "passed"
                    })
        # Sanitize commands for response (remove large binary data)
        def sanitize_commands_for_response(commands):
            """Remove large binary data from commands before sending response."""
            sanitized = []
            for cmd in commands:
                cmd_copy = cmd.copy()
                if "params" in cmd_copy:
                    params_copy = cmd_copy["params"].copy()
                    # Replace large binary data with summary
                    if "main_image_data" in params_copy and isinstance(params_copy["main_image_data"], dict):
                        img_data = params_copy["main_image_data"]
                        data_size = len(img_data.get('data', b'')) if isinstance(img_data.get('data'), bytes) else len(str(img_data.get('data', '')))
                        params_copy["main_image_data"] = {
                            "mime_type": img_data.get("mime_type"),
                            "data": f"<bytes:{data_size} bytes>"
                        }
                    if "reference_images" in params_copy and isinstance(params_copy["reference_images"], list):
                        params_copy["reference_images"] = f"<{len(params_copy['reference_images'])} reference images>"
                    cmd_copy["params"] = params_copy
                sanitized.append(cmd_copy)
            return sanitized

        # Prepare final response
        result = {
            "explanation": parsed_response.get("explanation", "Processed your request"),
            "commands": sanitize_commands_for_response(parsed_response.get("commands", [])),
            "expectedResult": parsed_response.get("expectedResult", "Commands executed"),
            "executionResults": execution_results,
            "modelUsed": selected_model  # Include which model was used for cost tracking
        }
        
        # Update session with this interaction and model preference if session_id provided
        if session_manager and session_context:
            # First add the interaction
            session_manager.add_interaction(session_id, user_input, result)
            logger.debug(f"Updated session {session_id} with interaction")
            
            # Note: Removed session-locked LLM model restriction - models can now be switched per request
        
        return result
    except AppError as e:
        # Re-raise AppError to be handled by HTTP layer
        e.log()
        raise
    except Exception as e:
        logger.error(f"Error in process_natural_language: {e}")
        return {
            "error": str(e),
            "explanation": "An error occurred while processing your request",
            "commands": [],
            "executionResults": [],
            "modelUsed": selected_model if 'selected_model' in locals() else "unknown"
        }

# Main function for external use with session support
def process_natural_language(user_input: str, context: str = None, session_id: str = None, llm_model: str = None, images: Optional[List[Dict[str, Any]]] = None, reference_images: Optional[List[Dict[str, Any]]] = None, target_image_uid: str = None, main_image_data: Optional[Dict[str, Any]] = None, main_prompt: str = None, reference_prompts: List[str] = None) -> Dict[str, Any]:
    """Process natural language input and return structured commands with optional session support."""
    try:
        return _process_natural_language_impl(user_input, context, session_id, llm_model, images, reference_images, target_image_uid, main_image_data, main_prompt, reference_prompts)
    except Exception as e:
        logger.error(f"Error in process_natural_language: {e}")
        return {
            "error": str(e),
            "explanation": "An error occurred while processing your request",
            "commands": [],
            "executionResults": [],
            "modelUsed": selected_model if 'selected_model' in locals() else "unknown"
        }

def build_system_prompt_with_session(context: str, session_context: SessionContext = None, is_style_request: bool = False) -> str:
    """Build system prompt with session context information."""
    import time
    import random
    timestamp = int(time.time() * 1000)
    random_suffix = random.randint(1000, 9999)
    
    # Check if we should use minimal prompt for style requests
    if is_style_request and session_context and session_context.get_latest_image_path():
        # Minimal prompt for style transformations - reduces ~75% token usage
        base_prompt = f"""Transform image styles for creative professionals.

**Commands:**
- transform_image_style: Apply style to latest image
**Reference Images:** WHEN reference_image_uids available, ALWAYS use transform_image_style
- Korean prompts: "ì´ í¬ì¦ˆë¥¼ ì·¨í•´ì£¼ì„¸ìš”" = take pose from reference, "ì´ ìƒ‰ê¹”ë¡œ" = use reference color
**Format:** {{"explanation": "desc", "commands": [{{"type": "command", "params": {{"style_prompt": "style desc", "intensity": 0.8}}}}], "expectedResult": "result"}}

Latest image available. Return valid JSON only."""
    else:
        # Get supported commands from registry for full prompt
        registry = get_command_registry()
        supported_commands = registry.get_supported_commands()
        
        base_prompt = f"""You are an AI assistant for creative professionals in their 20's (directors, cinematographers, technical artists) working with Unreal Engine for film, game development, and virtual production.

Your role is to provide intuitive creative control by translating natural language requests into precise Unreal Engine commands that support professional workflows and enable real-time creative iteration.

## SUPPORTED COMMANDS
**Scene Environment:**
- Ultra Dynamic Sky: get_ultra_dynamic_sky, set_time_of_day, set_color_temperature
- Ultra Dynamic Weather: get_ultra_dynamic_weather, set_current_weather_to_rain
- Geospatial: set_cesium_latitude_longitude, get_cesium_properties

**Scene Objects & Lighting:**
- Cinematic Lighting: create_mm_control_light, get_mm_control_lights, update_mm_control_light, delete_mm_control_light

**3D Content & Assets:**
- Roblox Avatars: download_and_import_roblox_avatar (RECOMMENDED: full pipeline - download, convert, import in one command), download_roblox_obj (download only), convert_roblox_obj_to_fbx (convert only), import_object3d_by_uid (import only)
- Asset Import: import_object3d_by_uid (import downloaded 3D objects as Unreal Editor assets)

**Rendering & Capture:**
- Screenshots: take_screenshot (take new screenshot, returns image URL)

**AI Image Editing (Nano Banana - Gemini 2.5 Flash Image):**
- transform_image_style: **ALWAYS USE THIS FOR ANY VISUAL REQUEST**
  * CAN DO: pose changes, character actions, style transfer, content modifications, object manipulation
  * Examples: "ì† ë“¤ì–´" â†’ style_prompt: "character raising hands", "ì–‘ì† ë“¤ì–´" â†’ style_prompt: "both hands up"
  * Auto-uses latest screenshot (target_image_uid provided automatically)
  * Supports reference images for style/composition guidance

**REFERENCE IMAGES PROCESSING:**
- WHEN reference images are provided (reference_image_uids available):
  * ALWAYS use transform_image_style command
  * Reference images + prompts = POWERFUL transformation capability
  * Korean prompts like "ì´ í¬ì¦ˆë¥¼ ì·¨í•´ì£¼ì„¸ìš”" = "take this pose from reference"
  * Examples: "ì´ ìƒ‰ê¹”ë¡œ" â†’ use reference color, "ì´ í¬ì¦ˆë¡œ" â†’ copy reference pose
  * System automatically loads reference images - YOU JUST GENERATE THE COMMAND

**CRITICAL**: transform_image_style uses AI image generation to MODIFY ANY VISUAL ASPECT
- Pose changes: YES âœ…
- Character actions: YES âœ…
- Add/remove objects: YES âœ…
- Scene modifications: YES âœ…
- Reference image guidance: YES âœ…

**AI Video Generation (Veo-3):**
- generate_video_from_image: Generate 8-second video from image
  * Auto-uses latest screenshot (target_image_uid provided automatically)
  * Requires explicit video request keywords

**COMMAND SELECTION RULES:**

**STEP-BY-STEP COMMAND SELECTION:**

**STEP 1: Check for Unreal Engine keywords FIRST**
- IF input contains: "ì–¸ë¦¬ì–¼ë¡œ", "ì–¸ë¦¬ì–¼ì—ì„œ", "ì–¸ë¦¬ì–¼", "ì”¬ì—ì„œ", "in Unreal", "in scene", "scene"
- THEN analyze the request and use appropriate 3D Scene commands:
  * "ìƒ‰ ì˜¨ë„ ë”°ëœ»í•˜ê²Œ" â†’ set_color_temperature
  * "ì‹œê°„ ë°”ê¿”" â†’ set_time_of_day
  * "ë¹„ ë‚´ë ¤" â†’ set_current_weather_to_rain
  * "ì¡°ëª… ë°ê²Œ" â†’ create_mm_control_light or update_mm_control_light
- STOP here, do NOT proceed to STEP 2, 3, or 4

**STEP 1.5: Check for Roblox keywords**
- IF input contains download + import keywords (e.g., "download AND import", "download and bring in", "ë‹¤ìš´ë¡œë“œí•˜ê³  ìž„í¬íŠ¸"):
- THEN use download_and_import_roblox_avatar (RECOMMENDED - handles full pipeline):
  * "download roblox avatar 3131 and import it" â†’ download_and_import_roblox_avatar with user_input: "3131"
  * "ë¡œë¸”ë¡ìŠ¤ ì•„ë°”íƒ€ BuildermanOG ë‹¤ìš´ë¡œë“œí•˜ê³  ê°€ì ¸ì™€" â†’ download_and_import_roblox_avatar with user_input: "BuildermanOG"
  * "get roblox user 12345 and bring it into unreal" â†’ download_and_import_roblox_avatar with user_input: "12345"
- ELSE IF input contains only download keywords: "roblox", "ë¡œë¸”ë¡ìŠ¤", "ì•„ë°”íƒ€ ë‹¤ìš´ë¡œë“œ", "download avatar", "download roblox", "get roblox"
- THEN use download_roblox_obj command:
  * "download roblox avatar for BuildermanOG" â†’ download_roblox_obj
  * "ë¡œë¸”ë¡ìŠ¤ ì•„ë°”íƒ€ ë‹¤ìš´ë¡œë“œí•´ì¤˜ user123" â†’ download_roblox_obj
  * "get roblox obj for 12345" â†’ download_roblox_obj
- ELSE IF input contains convert keywords: "convert", "ë³€í™˜", "fbxë¡œ ë³€í™˜", "to fbx", "obj to fbx"
- THEN use convert_roblox_obj_to_fbx command:
  * "convert obj_001 to fbx" â†’ convert_roblox_obj_to_fbx
  * "obj_001ì„ fbxë¡œ ë³€í™˜í•´ì¤˜" â†’ convert_roblox_obj_to_fbx
  * "convert roblox avatar to fbx" â†’ convert_roblox_obj_to_fbx (uses most recent obj_XXX UID)
- ELSE IF input contains import keywords: "import", "ìž„í¬íŠ¸", "ê°€ì ¸ì™€", "ë¶ˆëŸ¬ì™€", "bring into unreal"
- THEN use import_object3d_by_uid command:
  * "import the roblox avatar" â†’ import_object3d_by_uid (uses most recent obj_XXX UID)
  * "obj_001ì„ ìž„í¬íŠ¸í•´ì¤˜" â†’ import_object3d_by_uid with uid: obj_001
  * "bring the downloaded avatar into unreal" â†’ import_object3d_by_uid
- STOP here, do NOT proceed to STEP 2, 3, or 4

**STEP 2: Check for Video keywords**
- IF "ì–¸ë¦¬ì–¼" NOT found AND input contains: "ì˜ìƒ", "ë¹„ë””ì˜¤", "ë™ì˜ìƒ", "video"
- THEN use generate_video_from_image
- STOP here, do NOT proceed to STEP 3

**STEP 3: DEFAULT â†’ transform_image_style**
- IF STEP 1 and STEP 2 both failed
- THEN use transform_image_style for ANY visual request:
  * "ìƒ‰ ì˜¨ë„ ë”°ëœ»í•˜ê²Œ" (without "ì–¸ë¦¬ì–¼") â†’ transform_image_style
  * "ì‹œê°„ ë°”ê¿”" (without "ì–¸ë¦¬ì–¼") â†’ transform_image_style
  * "ë¹„ ë‚´ë ¤" (without "ì–¸ë¦¬ì–¼") â†’ transform_image_style
  * "ì† ë“¤ì–´" â†’ transform_image_style
  * "ì‚¬ì´ë²„íŽ‘í¬ë¡œ" â†’ transform_image_style
  * "ì´ í¬ì¦ˆë¥¼ ì·¨í•´ì£¼ì„¸ìš”" â†’ transform_image_style (WITH reference images)
  * "ì´ ìƒ‰ê¹”ë¡œ ë°”ê¿”ì£¼ì„¸ìš”" â†’ transform_image_style (WITH reference images)
  * "Transform using reference images" â†’ transform_image_style (WITH reference images)

**CRITICAL DECISION LOGIC:**
- "ì–¸ë¦¬ì–¼ë¡œ ìƒ‰ ì˜¨ë„ ë”°ëœ»í•˜ê²Œ" â†’ set_color_temperature âœ…
- "ìƒ‰ ì˜¨ë„ ë”°ëœ»í•˜ê²Œ" (no "ì–¸ë¦¬ì–¼") â†’ transform_image_style âœ…
- "ì–¸ë¦¬ì–¼ì—ì„œ ì‹œê°„ ë°”ê¿”" â†’ set_time_of_day âœ…
- "ì‹œê°„ ë°”ê¿”" (no "ì–¸ë¦¬ì–¼") â†’ transform_image_style âœ…

## PARAMETER RULES
**Essential Parameters:**
- time_of_day: HHMM format (600=6AM, 1200=noon, 1800=6PM)
- color_temperature: Kelvin (1500-15000) OR "warmer"/"cooler"
- style_prompt: Description for image transformations
- prompt: Description for video animation
- aspect_ratio: "16:9" or "9:16" (video only)
- resolution: "720p" or "1080p" (video only)
- user_input: Roblox username or user ID (required for download_roblox_obj and download_and_import_roblox_avatar)
- obj_uid: OBJ UID to convert (required for convert_roblox_obj_to_fbx, format: obj_XXX)
- uid: Object UID (required for import_object3d_by_uid, format: obj_XXX or fbx_XXX)

**Image/Video Source:**
- target_image_uid: Automatically provided (latest screenshot)
- reference_image_uids: Automatically provided when available
- DO NOT specify image_url or UIDs manually

## DECISION FLOWCHART

```
User Input: "ìƒ‰ ì˜¨ë„ ë”°ëœ»í•˜ê²Œ"
    â†“
STEP 1: Contains "ì–¸ë¦¬ì–¼"? â†’ NO
    â†“
STEP 2: Contains "ì˜ìƒ/video"? â†’ NO
    â†“
STEP 3: DEFAULT â†’ transform_image_style âœ…

User Input: "ì–¸ë¦¬ì–¼ë¡œ ìƒ‰ ì˜¨ë„ ë”°ëœ»í•˜ê²Œ"
    â†“
STEP 1: Contains "ì–¸ë¦¬ì–¼"? â†’ YES â†’ set_color_temperature âœ…
```

## EXAMPLES (CRITICAL FOR UNDERSTANDING)

**Same request, different command based on "ì–¸ë¦¬ì–¼" keyword:**

WITHOUT "ì–¸ë¦¬ì–¼" (â†’ transform_image_style):
- "ìƒ‰ ì˜¨ë„ ë”°ëœ»í•˜ê²Œ" â†’ transform_image_style âœ…
- "ì‹œê°„ ë°”ê¿”" â†’ transform_image_style âœ…
- "ë¹„ ë‚´ë ¤" â†’ transform_image_style âœ…
- "ì¡°ëª… ë°ê²Œ" â†’ transform_image_style âœ…
- "ì–‘ì† ë“¤ì–´" â†’ transform_image_style âœ…

WITH "ì–¸ë¦¬ì–¼" (â†’ 3D Scene Commands):
- "ì–¸ë¦¬ì–¼ë¡œ ìƒ‰ ì˜¨ë„ ë”°ëœ»í•˜ê²Œ" â†’ set_color_temperature âœ…
- "ì–¸ë¦¬ì–¼ì—ì„œ ì‹œê°„ ë°”ê¿”" â†’ set_time_of_day âœ…
- "ì–¸ë¦¬ì–¼ ì”¬ì— ë¹„ ë‚´ë ¤" â†’ set_current_weather_to_rain âœ…
- "ì–¸ë¦¬ì–¼ë¡œ ì¡°ëª… ë°ê²Œ" â†’ create_mm_control_light âœ…

WITH "video" (â†’ Video Generation):
- "ì˜ìƒ ìƒì„±í•´ì¤˜" â†’ generate_video_from_image âœ…
- "Create a video" â†’ generate_video_from_image âœ…

WITH "roblox" + "import" (â†’ Full Pipeline - RECOMMENDED):
- "download roblox avatar 3131 and import it" â†’ download_and_import_roblox_avatar âœ…
- "ë¡œë¸”ë¡ìŠ¤ ì•„ë°”íƒ€ BuildermanOG ë‹¤ìš´ë¡œë“œí•˜ê³  ê°€ì ¸ì™€" â†’ download_and_import_roblox_avatar âœ…
- "get roblox user 12345 and bring it into unreal" â†’ download_and_import_roblox_avatar âœ…

WITH "roblox" only (â†’ Roblox Download):
- "download roblox avatar for BuildermanOG" â†’ download_roblox_obj âœ…
- "ë¡œë¸”ë¡ìŠ¤ ì•„ë°”íƒ€ ë‹¤ìš´ë¡œë“œí•´ì¤˜ user123" â†’ download_roblox_obj âœ…
- "get roblox obj for 12345" â†’ download_roblox_obj âœ…

WITH "convert" (â†’ FBX Conversion):
- "convert obj_001 to fbx" â†’ convert_roblox_obj_to_fbx âœ…
- "obj_001ì„ fbxë¡œ ë³€í™˜í•´ì¤˜" â†’ convert_roblox_obj_to_fbx âœ…
- "convert roblox avatar to fbx" â†’ convert_roblox_obj_to_fbx âœ…

**RESPONSE FORMAT (MANDATORY):**
You MUST return valid JSON in this exact format:
{{
  "explanation": "Brief description of what you're doing",
  "commands": [
    {{
      "type": "command_name",
      "params": {{
        "style_prompt": "description here"
      }}
    }}
  ],
  "expectedResult": "What will happen"
}}

**CRITICAL RULES - READ CAREFULLY:**
1. NEVER say "cannot do", "not supported", "tools do not support" - transform_image_style CAN DO EVERYTHING
2. NEVER return empty commands array - ALWAYS return at least one command
3. For ANY visual request â†’ use transform_image_style
4. "ì† ë“¤ì–´", "raise hand", "change pose" â†’ transform_image_style (NOT "cannot do")

**EXAMPLE CORRECT RESPONSES:**
User: "ì†ì„ ë“¤ê²Œ í•´ì¤˜"
Response:
{{
  "explanation": "Modifying image to show character raising hands",
  "commands": [{{
    "type": "transform_image_style",
    "params": {{"style_prompt": "character raising both hands up"}}
  }}],
  "expectedResult": "Character will be shown with hands raised"
}}

User: "ì–‘ì† ë“¤ì–´"
Response:
{{
  "explanation": "Transforming image to show both hands raised",
  "commands": [{{
    "type": "transform_image_style",
    "params": {{"style_prompt": "both hands up in the air"}}
  }}],
  "expectedResult": "Image transformed with both hands raised"
}}

User: "download roblox avatar for BuildermanOG"
Response:
{{
  "explanation": "Downloading 3D Roblox avatar for user BuildermanOG",
  "commands": [{{
    "type": "download_roblox_obj",
    "params": {{"user_input": "BuildermanOG"}}
  }}],
  "expectedResult": "Roblox avatar 3D model downloaded with OBJ, MTL, and texture files"
}}

**ABSOLUTELY FORBIDDEN RESPONSES:**
âŒ "The current set of tools does not support..."
âŒ "My capabilities are focused on..."
âŒ "I cannot directly manipulate..."
âœ… INSTEAD: Always use transform_image_style with appropriate style_prompt"""

    # For style requests, skip complex session context to save tokens
    if not is_style_request and session_context:
        # Determine current conversation mode based on recent commands
        recent_commands = session_context.get_recent_commands(max_commands=3)
        current_mode = "3D Scene Mode"  # Default
        
        if recent_commands:
            # Check if recent commands were primarily 2D image editing
            image_commands = ['transform_image_style']
            recent_image_commands = [cmd for cmd in recent_commands if cmd.get('type') in image_commands]
            
            if len(recent_image_commands) >= len(recent_commands) // 2:  # 50% or more were image commands
                current_mode = "2D Image Mode"
        
        base_prompt += f"\n\n## CURRENT MODE: {current_mode}"
        if current_mode == "2D Image Mode":
            base_prompt += "\nContinue image editing workflow. For 'add X' use transform_image_style."
        else:
            base_prompt += "\nContinue 3D scene workflow. Use lighting, environment, weather commands."
        
        # Add brief scene state
        scene_summary = session_context.get_scene_summary()
        if scene_summary and scene_summary != "No scene state tracked yet.":
            base_prompt += f"\n\nScene: {scene_summary}"
        
        # Add latest image UID if available
        latest_image_uid = session_context.get_latest_image_uid()
        latest_filename = session_context.get_latest_image_path()
        if latest_image_uid and latest_filename:
            base_prompt += f"\nLatest image: {latest_image_uid} ({latest_filename}) - auto-used if image_url not specified"
        elif latest_filename:
            base_prompt += f"\nLatest image: {latest_filename} (no UID available)"
    
    base_prompt += f"\n\nContext: {context}\n\nJSON FORMAT:\n{{\n  \"explanation\": \"Brief description\",\n  \"commands\": [{{\"type\": \"command_name\", \"params\": {{...}}}}],\n  \"expectedResult\": \"What happens\"\n}}"
    
    return base_prompt


def execute_command_direct(command: Dict[str, Any]) -> Any:
    """Execute a command directly using appropriate handler system."""
    logger.info(f"execute_command_direct: Processing {command.get('type')} with params: {command.get('params', {})}")
    
    command_type = command.get('type')
    
    # Use command registry for unified execution
    registry = get_command_registry()
    
    # Check if this is a command that doesn't need Unreal Engine connection
    # Nano Banana: Image transformation (uses external API)
    # Roblox: Avatar downloads (uses Roblox API + local file storage)
    no_unreal_required_commands = [
        'transform_image_style',
        'download_roblox_obj',
        'get_roblox_download_status',
        'cancel_roblox_download',
        'convert_roblox_obj_to_fbx'
    ]

    if command_type in no_unreal_required_commands:
        logger.info(f"Executing {command_type} without Unreal Engine connection (standalone command)")
        result = registry.execute_command(command, None)
        
    else:
        # All other commands need Unreal Engine connection
        from tools.unreal_connection import get_unreal_connection
        unreal = get_unreal_connection()
        if not unreal:
            raise Exception("Could not connect to Unreal Engine")
        result = registry.execute_command(command, unreal)
    
    return result
