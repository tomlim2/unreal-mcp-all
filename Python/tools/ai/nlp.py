"""
MegaMelange Natural Language Processing Module

## Target User & Design Philosophy

**Primary User**: Creative professionals in their 20's (directors, cinematographers, technical artists) 
working with Unreal Engine for film, game development, and virtual production.

**Core Principles**:
- **Intuitive Creative Control**: Natural language commands for complex Unreal Engine operations
- **Professional Workflow Integration**: Support for industry-standard pipelines and tools
- **Real-time Iteration**: Immediate visual feedback for creative decision-making
- **Modular Extensibility**: Easy addition of new creative tools and rendering features
- **Cross-Platform Accessibility**: Web interface, MCP clients, and direct API access

This module translates natural language input from creative professionals into structured
Unreal Engine commands, enabling intuitive control over lighting, camera work, materials,
and scene composition through conversational interfaces.
"""

import logging
import json
from typing import Dict, List, Any, Optional
from .command_handlers import get_command_registry
from core.utils.path_manager import get_path_manager
from core.errors import AppError

# Get logger
logger = logging.getLogger("UnrealMCP")

def _attempt_json_completion(incomplete_json: str) -> str:
    """Attempt to complete an incomplete JSON response."""
    try:
        # Remove any trailing incomplete content
        content = incomplete_json.strip()
        
        # Find the last complete structure
        last_quote_pos = -1
        in_string = False
        escaped = False
        
        for i, char in enumerate(content):
            if escaped:
                escaped = False
                continue
            
            if char == '\\':
                escaped = True
                continue
                
            if char == '"' and not escaped:
                if not in_string:
                    in_string = True
                else:
                    in_string = False
                    last_quote_pos = i
        
        # If we're in the middle of a string, complete it
        if in_string and last_quote_pos != -1:
            # Find where the incomplete string starts
            string_start = content.rfind('"', 0, last_quote_pos)
            if string_start != -1:
                # Complete the string
                content = content[:string_start + 1] + content[string_start + 1:] + '"'
        
        # Now fix structural issues
        open_braces = content.count('{')
        close_braces = content.count('}')
        open_brackets = content.count('[')
        close_brackets = content.count(']')
        
        # Complete missing closing braces/brackets
        missing_braces = open_braces - close_braces
        missing_brackets = open_brackets - close_brackets
        
        # Add missing closes in logical order
        if missing_brackets > 0:
            content += ']' * missing_brackets
        if missing_braces > 0:
            content += '}' * missing_braces
            
        return content
        
    except Exception as e:
        logger.warning(f"JSON completion failed: {e}")
        return incomplete_json

def _resolve_image_path(filename: str) -> str:
    """Resolve image path based on file source - Unreal screenshots vs styled images."""
    import os

    # Get project paths using centralized path management (with built-in fallbacks)
    path_manager = get_path_manager()
    screenshots_dir_path = path_manager.get_unreal_screenshots_path()
    styled_dir_path = path_manager.get_unreal_styled_images_path()

    # If centralized path management fails completely, return filename as-is
    if not screenshots_dir_path or not styled_dir_path:
        return filename

    # Just filename provided - need to determine the correct directory
    if not os.path.dirname(filename):
        # Check if this looks like a styled image (generated by 2D editing)
        if 'styled_' in filename or filename.endswith('_styled.png') or filename.endswith('_styled.jpg'):
            # This is a styled image - look in styled directory
            styled_path = os.path.join(styled_dir_path, filename)
            if os.path.exists(styled_path):
                return styled_path

        # Check standard Unreal screenshots directory first
        unreal_path = os.path.join(screenshots_dir_path, filename)
        if os.path.exists(unreal_path):
            return unreal_path

        # Check styled directory as fallback
        styled_path = os.path.join(styled_dir_path, filename)
        if os.path.exists(styled_path):
            return styled_path

        # If file doesn't exist in either location, default to Unreal screenshots
        # (the command handler will handle the file not found error)
        return unreal_path

    # Full or relative path provided - return as-is
    return filename

def _extract_from_partial_response(partial_response: str) -> dict:
    """Extract meaningful information from a partial/malformed AI response."""
    try:
        import re

        # Check if this is a conversational response (no command structure)
        # Conversational responses don't have JSON structure and should be passed through as-is
        if not re.search(r'\{|\[|"type":|"command":', partial_response):
            # This is a pure conversational response
            return {
                "explanation": partial_response.strip(),
                "commands": [],
                "expectedResult": "",
                "conversational": True
            }

        # Default response structure for partial JSON
        result = {
            "explanation": "Processing your request based on partial AI response",
            "commands": [],
            "expectedResult": "Command extracted from incomplete response"
        }
        
        # Try to extract explanation
        explanation_match = re.search(r'"explanation":\s*"([^"]*)', partial_response)
        if explanation_match:
            result["explanation"] = explanation_match.group(1)
        
        # Try to extract command type and parameters
        command_type_match = re.search(r'"type":\s*"([^"]*)', partial_response)
        if command_type_match:
            command_type = command_type_match.group(1)
            
            # Initialize command structure
            command = {
                "type": command_type,
                "params": {}
            }
            
            # Extract common parameters based on command type
            if command_type == "image_to_image":
                # Extract style_prompt
                style_match = re.search(r'"style_prompt":\s*"([^"]*)', partial_response)
                if style_match:
                    command["params"]["style_prompt"] = style_match.group(1)
                else:
                    # Infer from content - look for style descriptions
                    if "Japan" in partial_response or "punk" in partial_response:
                        command["params"]["style_prompt"] = "Japan punk style"
                
                # Extract image_path or image_url from partial response
                image_path_match = re.search(r'"image_path":\s*"([^"]*)', partial_response)
                image_url_match = re.search(r'"image_url":\s*"([^"]*)', partial_response)

                if image_path_match:
                    command["params"]["image_path"] = _resolve_image_path(image_path_match.group(1))
                elif image_url_match:
                    command["params"]["image_path"] = _resolve_image_path(image_url_match.group(1))
                
                # Add default parameters
                command["params"]["intensity"] = 0.8
                
            elif command_type == "take_screenshot":
                # Extract resolution multiplier
                res_match = re.search(r'"resolution_multiplier":\s*([0-9.]+)', partial_response)
                if res_match:
                    command["params"]["resolution_multiplier"] = float(res_match.group(1))
                else:
                    command["params"]["resolution_multiplier"] = 2.0
                command["params"]["include_ui"] = False

            elif command_type == "generate_video_from_image":
                # Extract prompt (required)
                prompt_match = re.search(r'"prompt":\s*"([^"]*)', partial_response)
                if prompt_match:
                    command["params"]["prompt"] = prompt_match.group(1)

                # Extract image_url (optional)
                image_url_match = re.search(r'"image_url":\s*"([^"]*)', partial_response)
                if image_url_match:
                    command["params"]["image_url"] = image_url_match.group(1)

                # Extract aspect_ratio (optional)
                aspect_ratio_match = re.search(r'"aspect_ratio":\s*"([^"]*)', partial_response)
                if aspect_ratio_match:
                    command["params"]["aspect_ratio"] = aspect_ratio_match.group(1)

                # Extract resolution (optional)
                resolution_match = re.search(r'"resolution":\s*"([^"]*)', partial_response)
                if resolution_match:
                    command["params"]["resolution"] = resolution_match.group(1)
            
            result["commands"] = [command]
            result["expectedResult"] = f"Executing {command_type} based on partial response"
        
        logger.info(f"Extracted command from partial response: {result}")
        return result
        
    except Exception as e:
        logger.error(f"Failed to extract from partial response: {e}")
        return {
            "explanation": "Unable to process the request due to response parsing error",
            "commands": [],
            "expectedResult": "Please try rephrasing your request"
        }

# Import session management
from core.session import get_session_manager, SessionContext

# Import model providers
from .model_providers import get_model_provider, get_default_model, get_available_models

# Import data models and prompts
from .models import ProcessingRequest, ProcessingResponse
from .prompts import get_minimal_prompt, get_full_prompt
from .prompts.system_prompt import get_conversational_suffix


def _auto_assign_latest_image_if_needed(command, session_context):
    """ì´ë¯¸ì§€ ê´€ë ¨ ëª…ë ¹ì— ìµœì‹  ì´ë¯¸ì§€ UID ìžë™ í• ë‹¹

    IMPORTANT: Only assigns image UIDs (img_XXX), never video UIDs (vid_XXX).
    """
    if not command.get("params"):
        command["params"] = {}

    params = command["params"]
    command_type = command.get("type")

    # Image-related commands (commands that require source images)
    image_commands = ["image_to_image", "generate_video_from_image"]

    # Text-to-image commands (commands that DON'T require source images)
    text_to_image_commands = ["text_to_image"]

    # Check if image parameter already provided
    has_image = ("image_url" in params or "image_uid" in params or
                 "target_image_uid" in params or "main_image_data" in params)

    # Skip auto-assignment for text-to-image commands (they don't need source images)
    if command_type in text_to_image_commands:
        logger.info(f"Skipping auto-assignment for {command_type} (text-to-image, no source image needed)")
        return

    if command_type in image_commands and not has_image:
        logger.info(f"Attempting auto-assignment for {command_type} (has_image={has_image}, session_context={session_context is not None})")

        latest_uid = None

        # Try 1: Get from session conversation history (preferred for session-based workflow)
        if session_context:
            latest_uid = session_context.get_latest_image_uid()
            logger.info(f"Retrieved from session context: latest_uid={latest_uid}")

        # Try 2: Get from UID manager directly (fallback for global latest image)
        if not latest_uid:
            from core.resources.uid_manager import get_latest_image_uid as get_global_latest_image_uid
            latest_uid = get_global_latest_image_uid()
            logger.info(f"Retrieved from UID manager: latest_uid={latest_uid}")

        # Double-check: ensure we only use image UIDs, never video UIDs
        if latest_uid and latest_uid.startswith('img_'):
            # Assign latest image UID to appropriate parameter
            if command_type == "image_to_image":
                params["target_image_uid"] = latest_uid
                logger.info(f"âœ… Auto-assigned latest image UID for {command_type}: {latest_uid}")
            elif command_type == "generate_video_from_image":
                params["image_url"] = latest_uid
                logger.info(f"âœ… Auto-assigned latest image UID for {command_type}: {latest_uid}")
        else:
            logger.warning(f"âŒ No valid image UID found for {command_type} (latest_uid: {latest_uid})")


def _extract_style_essence(user_input: str, provider) -> str:
    """Extract only style-related content from user input to reduce tokens."""
    try:
        # Very minimal prompt for style extraction
        extraction_prompt = """Extract only the visual style/effect from this request. Keep it under 10 words.

Examples:
- "Make it cyberpunk style with neon lights" â†’ "cyberpunk neon"
- "ì‚¬ì´ë²„íŽ‘í¬ ìŠ¤íƒ€ì¼ë¡œ ë°”ê¿”ì¤˜" â†’ "cyberpunk style"  
- "Apply watercolor effect to the image" â†’ "watercolor effect"
- "Transform to anime style" â†’ "anime style"

Input: {input}
Style:"""

        messages = [{
            "role": "user", 
            "content": extraction_prompt.format(input=user_input)
        }]
        
        # Use minimal tokens for extraction
        style_essence = provider.generate_response(
            messages=messages,
            system_prompt="Extract visual style keywords only. Be concise.",
            max_tokens=50,  # Very small - just need style keywords
            temperature=0.0  # Deterministic
        )
        
        # Clean up the response
        style_essence = style_essence.strip().strip('"').strip("'")
        
        # Fallback if extraction failed
        if not style_essence or len(style_essence) > 50:
            # Simple keyword extraction fallback
            style_keywords = ['cyberpunk', 'anime', 'watercolor', 'punk', 'neon', 'vintage', 'dark', 'bright']
            found_keywords = [kw for kw in style_keywords if kw in user_input.lower()]
            style_essence = ' '.join(found_keywords) if found_keywords else user_input
        
        logger.info(f"Style extraction: '{user_input}' â†’ '{style_essence}'")
        return style_essence
        
    except Exception as e:
        logger.warning(f"Style extraction failed: {e}")
        return user_input  # Fallback to original


def _sanitize_commands_for_response(commands: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Remove large binary data from commands before sending response."""
    sanitized = []
    for cmd in commands:
        cmd_copy = cmd.copy()
        if "params" in cmd_copy:
            params_copy = cmd_copy["params"].copy()
            # Replace large binary data with summary
            if "main_image_data" in params_copy and isinstance(params_copy["main_image_data"], dict):
                img_data = params_copy["main_image_data"]
                data_size = len(img_data.get('data', b'')) if isinstance(img_data.get('data'), bytes) else len(str(img_data.get('data', '')))
                params_copy["main_image_data"] = {
                    "mime_type": img_data.get("mime_type"),
                    "data": f"<bytes:{data_size} bytes>"
                }
            if "reference_images" in params_copy and isinstance(params_copy["reference_images"], list):
                params_copy["reference_images"] = f"<{len(params_copy['reference_images'])} reference images>"
            cmd_copy["params"] = params_copy
        sanitized.append(cmd_copy)
    return sanitized


def _process_images_for_commands(commands: List[Dict[str, Any]], target_image_uid: str = None, main_image_data: Optional[Dict[str, Any]] = None, reference_images: Optional[List[Dict[str, Any]]] = None) -> None:
    """
    Inject image data into commands that support image processing.

    Args:
        commands: List of AI-generated commands to process
        target_image_uid: Optional UID for main target image (existing screenshot)
        main_image_data: Optional user-uploaded main image (in-memory only, no UID)
        reference_images: Optional list of reference images (in-memory only, no UID)
    """
    if not target_image_uid and not main_image_data and not reference_images:
        return

    # Commands that support image processing
    image_commands = {
        'image_to_image',
        'text_to_image',  # Also supports reference images for style
        'compose_images',
        'blend_images',
        'transfer_style'
    }

    for command in commands:
        command_type = command.get('type')

        if command_type in image_commands:
            if 'params' not in command:
                command['params'] = {}

            # Special case: text_to_image does NOT use main_image_data or target_image_uid
            # It only uses reference_images for style guidance
            if command_type != 'text_to_image':
                # Priority 1: Add user-uploaded main image (in-memory, no UID) - takes precedence over auto-fetched UID
                if main_image_data:
                    command['params']['main_image_data'] = main_image_data
                    logger.info(f"Added user-uploaded main image ({main_image_data.get('mime_type')}, {len(main_image_data.get('data', b''))//1024}KB) to command {command_type}")
                # Priority 2: Add target image UID if provided (existing screenshot or auto-fetched)
                elif target_image_uid:
                    command['params']['target_image_uid'] = target_image_uid
                    logger.info(f"Added target image UID {target_image_uid} to command {command_type}")

            # Add reference images if provided (in-memory only, no UID)
            # For text_to_image, reference images are used for style guidance only
            if reference_images and len(reference_images) > 0:
                command['params']['reference_images'] = reference_images
                logger.info(f"Added {len(reference_images)} reference images to command {command_type}")


def _setup_session_and_model(request: ProcessingRequest):
    """Setup session context and model provider."""
    session_manager = None
    session_context = None

    if request.session_id:
        session_manager = get_session_manager()
        session_context = session_manager.get_or_create_session(request.session_id)
        logger.info(f"Using session context: {request.session_id}")
    else:
        logger.info("No session ID provided, processing without session context")

    # Determine which model to use
    selected_model = request.llm_model or get_default_model()
    logger.info(f"Using model: {selected_model}")

    # Get the model provider
    provider = get_model_provider(selected_model)
    if not provider:
        # If user explicitly requested a specific model, return error (no fallback)
        if request.llm_model:
            error_msg = f"Requested model '{request.llm_model}' is not available or not configured"
            return None, None, None, selected_model, error_msg
        else:
            # If using default model and it's not available, return configuration error
            error_msg = f"Default model '{selected_model}' is not available. Configure GOOGLE_API_KEY or ANTHROPIC_API_KEY"
            return None, None, None, selected_model, error_msg

    return session_manager, session_context, provider, selected_model, None


def _prepare_messages(request: ProcessingRequest, session_context, is_style_request: bool) -> List[Dict[str, Any]]:
    """Build messages list including conversation history."""
    messages = []

    # Add conversation history as proper messages
    if session_context and session_context.conversation_history:
        # For style requests, use minimal history
        max_history = 2 if is_style_request else 4
        recent_messages = session_context.conversation_history[-max_history:]
        for msg in recent_messages:
            if msg.role in ['user', 'assistant']:
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })

    # Add current user input as the final message
    messages.append({
        "role": "user",
        "content": f"User request: {request.user_input}"
    })

    return messages


def _parse_ai_response(ai_response: str) -> Dict[str, Any]:
    """Parse AI response with JSON error recovery."""
    try:
        return json.loads(ai_response)
    except json.JSONDecodeError as e:
        logger.warning(f"Failed to parse AI response as JSON: {e}")
        logger.warning(f"Raw AI response: {repr(ai_response)}")

        # Try to fix common JSON issues first
        fixed_response = ai_response.strip()

        # Implement comprehensive JSON completion
        fixed_response = _attempt_json_completion(fixed_response)

        # Try parsing the fixed response
        try:
            parsed_response = json.loads(fixed_response)
            logger.info("Successfully fixed and parsed JSON response")
            return parsed_response
        except json.JSONDecodeError:
            # Try to extract JSON from response (which often includes explanatory text)
            import re
            json_match = re.search(r'\{[\s\S]*\}', ai_response)
            if json_match:
                try:
                    json_text = json_match.group()
                    parsed_response = json.loads(json_text)
                    logger.info("Successfully extracted JSON from AI response")
                    return parsed_response
                except json.JSONDecodeError:
                    logger.warning("Extracted text is also not valid JSON")
                    # Fall back to content extraction
                    return _extract_from_partial_response(ai_response)
            else:
                # No JSON structure found, fall back to content extraction
                return _extract_from_partial_response(ai_response)


def _execute_commands(request: ProcessingRequest, commands: List[Dict[str, Any]], session_context) -> List[Dict[str, Any]]:
    """Execute commands and return execution results."""
    execution_results = []

    for command in commands:
        try:
            logger.info(f"Executing command from NLP: {command}")

            # Add session_id to command params if session_id is provided
            if request.session_id:
                if "params" not in command:
                    command["params"] = {}
                command["params"]["session_id"] = request.session_id
                logger.debug(f"Added session_id {request.session_id} to command {command.get('type')}")

            # Add new prompt fields for enhanced reference images flow
            if request.main_prompt is not None or request.reference_prompts is not None:
                if "params" not in command:
                    command["params"] = {}

                if request.main_prompt is not None:
                    command["params"]["main_prompt"] = request.main_prompt
                    logger.info(f"ðŸŽ¯ Added main_prompt to {command.get('type')}: '{request.main_prompt}'")

                if request.reference_prompts is not None and len(request.reference_prompts) > 0:
                    # Filter out empty prompts
                    non_empty_prompts = [p for p in request.reference_prompts if p and p.strip()]
                    if non_empty_prompts:
                        command["params"]["reference_prompts"] = non_empty_prompts
                        logger.info(f"ðŸŽ¯ Added {len(non_empty_prompts)} reference_prompts to {command.get('type')}: {non_empty_prompts}")

            # Auto-assign latest image for image-related commands if needed
            _auto_assign_latest_image_if_needed(command, session_context)

            result = execute_command_direct(command)
            execution_results.append({
                "command": command.get("type", "unknown"),
                "success": True,
                "result": result,
                "validation": "passed"
            })
            logger.info(f"Successfully executed validated command: {command.get('type')}")
        except AppError as e:
            # Handle structured errors from command handlers
            e.log()
            error_response = e.to_response()["error"]  # Get structured error format
            execution_results.append({
                "command": command.get("type", "unknown"),
                "success": False,
                "error": error_response["message"],
                "error_code": error_response["code"],
                "category": error_response["category"],
                "error_details": error_response.get("details"),
                "suggestion": error_response.get("suggestion"),
                "validation": "passed"  # AppError means validation passed but execution failed
            })
        except Exception as e:
            # Handle unexpected errors
            logger.error(f"Failed to execute command {command.get('type')}: {e}")
            execution_results.append({
                "command": command.get("type", "unknown"),
                "success": False,
                "error": str(e),
                "validation": "failed" if "validation failed" in str(e).lower() else "passed"
            })

    return execution_results


def _process_natural_language_impl(user_input: str, context: str = None, session_id: str = None, llm_model: str = None, target_image_uid: str = None, main_image_data: Optional[Dict[str, Any]] = None, main_prompt: str = None, reference_prompts: List[str] = None, reference_images: Optional[List[Dict[str, Any]]] = None) -> Dict[str, Any]:
    try:
        # Create request object
        request = ProcessingRequest(
            user_input=user_input,
            context=context or "Assume as you are a creative cinematic director",
            session_id=session_id,
            llm_model=llm_model,
            target_image_uid=target_image_uid,
            main_image_data=main_image_data,
            main_prompt=main_prompt,
            reference_prompts=reference_prompts or [],
            reference_images=reference_images or []
        )

        # Setup session and model
        session_manager, session_context, provider, selected_model, error_msg = _setup_session_and_model(request)
        if error_msg:
            return {
                "error": error_msg,
                "explanation": f"The '{selected_model}' model is not available. Please check your API key configuration.",
                "commands": [],
                "executionResults": [],
                "modelUsed": selected_model
            }

        # Determine if this is a style or video request for preprocessing
        is_style_request = any(keyword in request.user_input.lower() for keyword in ['style', 'cyberpunk', 'anime', 'watercolor', 'punk', 'transform', 'make it'])
        is_video_request = any(keyword in request.user_input.lower() for keyword in ['video', 'animate', 'motion', 'movement', 'fly through', 'camera movement', 'flying camera', 'moving'])

        # For style requests, extract only the style essence to reduce tokens
        processed_input = request.user_input
        if is_style_request and session_context and session_context.get_latest_image_path():
            processed_input = _extract_style_essence(request.user_input, provider)
            logger.info(f"Style preprocessing: '{request.user_input}' â†’ '{processed_input}'")

        # Build system prompt with session context
        system_prompt = build_system_prompt_with_session(request.context, session_context, is_style_request or is_video_request)
        logger.info(f"Processing natural language input with {provider.get_model_name()}: {request.user_input}")

        # Prepare messages with conversation history
        messages = _prepare_messages(
            ProcessingRequest(
                user_input=processed_input,
                context=request.context,
                session_id=request.session_id
            ),
            session_context,
            is_style_request
        )

        # Generate AI response
        ai_response = provider.generate_response(
            messages=messages,
            system_prompt=system_prompt,
            max_tokens=4096,
            temperature=0.1
        )
        logger.info(f"AI response from {provider.get_model_name()} for '{request.user_input}': {ai_response}")

        # Parse AI response with error recovery
        parsed_response = _parse_ai_response(ai_response)

        # Process images for commands if images are provided
        if (request.target_image_uid or request.main_image_data or request.reference_images) and parsed_response.get("commands"):
            _process_images_for_commands(
                parsed_response["commands"],
                request.target_image_uid,
                request.main_image_data,
                request.reference_images
            )

        # Execute commands
        execution_results = []
        if parsed_response.get("commands") and isinstance(parsed_response["commands"], list):
            execution_results = _execute_commands(request, parsed_response["commands"], session_context)

        # Prepare final response
        result = {
            "explanation": parsed_response.get("explanation", "Processed your request"),
            "commands": _sanitize_commands_for_response(parsed_response.get("commands", [])),
            "expectedResult": parsed_response.get("expectedResult", "Commands executed"),
            "executionResults": execution_results,
            "modelUsed": selected_model
        }

        # Update session with this interaction if session_id provided
        if session_manager and session_context:
            session_manager.add_interaction(request.session_id, request.user_input, result)
            logger.debug(f"Updated session {request.session_id} with interaction")

        return result
    except AppError as e:
        # Re-raise AppError to be handled by HTTP layer
        e.log()
        raise
    except Exception as e:
        logger.error(f"Error in process_natural_language: {e}")
        return {
            "error": str(e),
            "explanation": "An error occurred while processing your request",
            "commands": [],
            "executionResults": [],
            "modelUsed": selected_model if 'selected_model' in locals() else "unknown"
        }

# Main function for external use with session support
def process_natural_language(user_input: str, context: str = None, session_id: str = None, llm_model: str = None, target_image_uid: str = None, main_image_data: Optional[Dict[str, Any]] = None, main_prompt: str = None, reference_prompts: List[str] = None, reference_images: Optional[List[Dict[str, Any]]] = None) -> Dict[str, Any]:
    """Process natural language input and return structured commands with optional session support."""
    return _process_natural_language_impl(user_input, context, session_id, llm_model, target_image_uid, main_image_data, main_prompt, reference_prompts, reference_images)

def build_system_prompt_with_session(context: str, session_context: SessionContext = None, is_style_request: bool = False) -> str:
    """Build system prompt with session context information."""
    # Check if we should use minimal prompt for style requests
    if is_style_request and session_context and session_context.get_latest_image_path():
        # Minimal prompt for style transformations - reduces ~75% token usage
        base_prompt = get_minimal_prompt()
    else:
        # Use full prompt with all command documentation
        base_prompt = get_full_prompt()

    # For style requests, skip complex session context to save tokens
    if not is_style_request and session_context:
        # Determine current conversation mode based on recent commands
        recent_commands = session_context.get_recent_commands(max_commands=3)
        current_mode = "3D Scene Mode"  # Default
        
        if recent_commands:
            # Check if recent commands were primarily 2D image editing
            image_commands = ['image_to_image']
            recent_image_commands = [cmd for cmd in recent_commands if cmd.get('type') in image_commands]
            
            if len(recent_image_commands) >= len(recent_commands) // 2:  # 50% or more were image commands
                current_mode = "2D Image Mode"
        
        base_prompt += f"\n\n## CURRENT MODE: {current_mode}"
        if current_mode == "2D Image Mode":
            base_prompt += "\nContinue image editing workflow. For 'add X' use image_to_image."
        else:
            base_prompt += "\nContinue 3D scene workflow. Use lighting, environment, weather commands."
        
        # Add brief scene state
        scene_summary = session_context.get_scene_summary()
        if scene_summary and scene_summary != "No scene state tracked yet.":
            base_prompt += f"\n\nScene: {scene_summary}"
        
        # Add latest image UID if available
        latest_image_uid = session_context.get_latest_image_uid()
        latest_filename = session_context.get_latest_image_path()
        if latest_image_uid and latest_filename:
            base_prompt += f"\nLatest image: {latest_image_uid} ({latest_filename}) - auto-used if image_url not specified"
        elif latest_filename:
            base_prompt += f"\nLatest image: {latest_filename} (no UID available)"

    # Add context and conversational suffix
    base_prompt += f"\n\nContext: {context}"
    base_prompt += get_conversational_suffix()

    return base_prompt


def execute_command_direct(command: Dict[str, Any]) -> Any:
    """Execute a command directly using appropriate handler system."""
    logger.info(f"execute_command_direct: Processing {command.get('type')} with params: {command.get('params', {})}")
    
    command_type = command.get('type')
    
    # Use command registry for unified execution
    registry = get_command_registry()
    
    # Check if this is a command that doesn't need Unreal Engine connection
    # AI Image Generation/Editing: Uses external APIs (Gemini)
    # Roblox: Avatar downloads (uses Roblox API + local file storage)
    no_unreal_required_commands = [
        'text_to_image',  # Text-to-image generation
        'image_to_image',      # Image-to-image transformation
        'download_roblox_obj',
        'get_roblox_download_status',
        'cancel_roblox_download',
        'convert_roblox_obj_to_fbx'
    ]

    if command_type in no_unreal_required_commands:
        logger.info(f"Executing {command_type} without Unreal Engine connection (standalone command)")
        result = registry.execute_command(command, None)
        
    else:
        # All other commands need Unreal Engine connection
        from tools.unreal_connection import get_unreal_connection
        unreal = get_unreal_connection()
        if not unreal:
            raise Exception("Could not connect to Unreal Engine")
        result = registry.execute_command(command, unreal)
    
    return result
